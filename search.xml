<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Git的一些基本操作]]></title>
    <url>%2F2019%2F06%2F27%2FGit%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Git的一些基本操作 设置SSH KEY ssh-keygen -t rsa -C &quot;yangbinh@yonyou.com&quot; -f &apos;~/.ssh/id_rsa_gitlab&apos; fork 操作 可以通过在github/gitlab上，点击 fork 进行操作将已有的项目fork到自己的repository中 Clone 操作 git clone &lt;repository_url&gt; 创建分支 根据本地分支创建： git branch &lt;branch_name&gt; 根据远程分支创建 git checkout -b &lt;branch_name&gt; origin/&lt;branch_name&gt; 创建remote git remote add &lt;remote_name&gt; &lt;remoet_url&gt; 更新remote git remote update &lt;remote_name&gt; &lt;remoet_url&gt; 更新remote的url地址 git remote set-url &lt;remote_name&gt; &lt;remoet_url&gt; 删除remote git remote remove &lt;remote_name&gt; 同步上游 - fetch命令 git fetch --all git fetch &lt;remote_name&gt; git fetch &lt;remote_name&gt; &lt;branch_name&gt; 更新本地分支 git pull &lt;remote_name&gt; &lt;branch_name&gt; 删除/强制删除本地分支 git branch -d &lt;branch_name&gt; git branch -D &lt;branch_name&gt; 合并指定分支到当前分支 git merge &lt;branch_name&gt; 回退远程分支 git log --online -10 git reset --hard &lt;commit_id&gt; git git push --force 清除本地文件提交状态 git rm -r --cached &lt;file&gt; git rm --cached . 本地分支与远程分支建立映射关系 git branch --set-upstream &lt;remote_name&gt;/&lt;branch_name&gt; 基于远程分支创建本地分支 创建并切换到新建的分支 git checkout -b &lt;local_branch_name&gt; &lt;remote_name&gt;/&lt;remote_branch_name&gt; 仅仅创建不切换 git fetch origin &lt;local_branch_name&gt; &lt;remote_name&gt;/&lt;remote_branch_name&gt; 暂存本地的修改 暂存时使用默认的备注信息 git stash 暂存指定备注信息 git stash push -m &lt;message&gt; 查看所有暂存 git stash list 获取使用某个暂存 git stash apply [stash@{1}] 恢复使用某个暂存同时删除该暂存 git stash pop [stash@{1}] 删除某个暂存 git stash drop [stash@{1}] 清空暂存 git stash clear 显示某个暂存 git stash show [stash@{1}] 放弃本地某个文件的修改 未进行add操作 git checkout -- &lt;file_path&gt; git checkout . 已进行add未进行commit git reset HEAD &lt;file_path&gt; git reset HEAD . 已进行commit，未push 回退到上一次commit的状态 git reset --hard HEAD^ 回退到任意版本 git reset --hard &lt;commit_id&gt; 删除commit 删除中间的某个commit git rebase -i &lt;commit_id&gt; 删除指定的commit之后的所有的commit git reset --hard &lt;commit_id&gt; 最近的一次提交内容归到上一次的commit中 git commit -amend 删除 untracked files git clean -f 连 untracked 的目录也一起删掉 git clean -fd 连 gitignore 的untrack 文件/目录也一起删掉 （慎用） git clean -xfd 在用上述 git clean 前，墙裂建议加上 -n 参数来先看看会删掉哪些文件，防止重要文件被误删 git clean -nxfd git clean -nf git clean -nfd 基于tag创建分支 git branch &lt;new-branch-name&gt; &lt;tag-name&gt; git merge命令若报错: refusing to merge unrelated histories git merge &lt;branch-name&gt; --allow-unrelated-histories 批量删除远程分支 git branch -r |grep -E -v &apos;master|upstream&apos; | sed &apos;s/origin\// /g&apos; |xargs git push -d &lt;remote_name&gt; 解释说明 git branch -r: 获取所有的远程分支 grep -E： 使用正则表达式筛选结果 grep -v：将筛选结果反选 sed ‘s/需要被替换的字符串/替换后的字符串/g’: 批量替换每行指定字符串 使用管道命令 |xargs 将参数传给命令 git push -d origin]]></content>
      <categories>
        <category>版本控制</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ命令行工具 CLI Tools]]></title>
    <url>%2F2019%2F06%2F21%2FRabbitMQ%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%20CLI-Tools%2F</url>
    <content type="text"><![CDATA[RabbitMQ命令行工具 CLI ToolsRabbitMQ主要有四个命令行工具 Commend Line Tools，不同的命令行适用不用的场景 rabbitmqctl：负责服务管理和进行操作 rabbitmq-diagnostics：负责系统诊断和健康检查 rabbitmq-plugins：负责插件管理 rabbitmqadmin：用来操作 HTTP API 系统环境要求 CLI Tools要求当前系统必须安装Erlang环境，具体的兼容版本可以参照： RabbitMQ的Erlang版本要求 CLI Tools要求当前系统编码设置是UTF-8(例如：en_GB.UTF-8 or en_US.UTF-8)，否则将会出现警告信息 rabbitmqctl命令rabbitmqctl 使用服务节点间共享的机密认证，该命令主要的功能包括以下几点： 停止节点运行 获取节点状态、有效配置、健康检查 Virtual Hosts管理 用户和权限管理 Policy管理 查看queues、connections、channels、exchanges和consumers列表信息 集群会员身份管理 rabbitmq-plugins命令rabbitmq-plugins 是一个管理多种插件的命令，包括获取插件列表以及启用/停用，是跟随RabbitMQ一起安装的。支持在线和离线模式，离线模式下做的改动会在节点重新启动时生效。rabbitmq-plugins 使用服务节点间共享的机密认证 关于节点的名称 Node NameRabbitMQ集群中的节点标识和互相通信都使用该节点的唯一标识-该节点名称，节点名称有前缀(通常是rabbit)和主机名构成，例如：`rabbit@node1.messaging.svc.local`。 如果在一台主机上同时启动多个节点则节点前缀部分一定不能相同，例如：rabbit1@hostname 和 rabbit2@hostname。CLI tools识别节点地址就是通过该节点的名称，大部分的CLI命令都会通过 --noe或者 -n 参数指定目标节点。 当一个节点启动的时候，会自动校验是否被分配了名称，该节点名称可以通过环境变量 RABBITMQ_NODENAME 来明确指定，如果没有设置，则默认会取 rabbit+本机的hostname。如果系统用的是全限定域名(FQDN)，有两种方案选择： 节点必须配置环境变量 RABBITMQ_USE_LONGNAME 为 true 在命令最后添加 --longnames 选项 CLI Tools认证和节点间通信认证集群中每个节点之间是否可以进行通信，还依赖于这两个节点上保存的 Erlang Cookie 是否相同，一个集群中的所有节点的Erlang Cookie 应该是相同的。这个值是一个由字母和数字组成的字符串，最大字符数是255，保存在节点所在的主机文件中。 如果没有指定每个节点启动的时候Erlang VM会随机生成一个Erlang Cookie，并且自动的创建一个文件用来存放，这种方式每次生成的Erlang Cookie都不相同，不适合生产环境。unix和windows系统上该文件的存放位置不同(注：需要确保该文件的使用者有足够的权限) Cookie文件的地址 UNIX系统存放位置： 节点之前通信使用：/var/lib/rabbitmq/.erlang.cookie CLI Tools使用：$HOME/.erlang.cookie WINDOWS系统存放位置：不同的Erlang版本存放位置不同，具体可以参考：Cookie文件说明 最不安全的设置Cookie方式 可以通过设置节点的环境变量 RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS 为 -setcookie &lt;cookie-value&gt; 来设置cookie值。但是这种方式是最不安全的方式，不推荐使用 rabbitmqadmin命令rabbitmqadmin 命令是构建在 HTTP API 的基础上，该工具要求 Python 2.7.9 或者以上版本。 rabbitmqadmin 使用 HTTP API 的认证机制，基于HTTP认证，该命令默认并没有集成到RabbitMQ安装包中，需要额外的进行安装才能使用 命令别名rabbitmqctl, rabbitmq-diagnostics 和 rabbitmq-plugins 都支持命令别名设置，命令别名提供一种更加简短的命令版本以及命令参数。例如，命令 rabbitmqctl environment 可以通过命令别名设置为 rabbitmqctl env来达到同样的目的。 命令别名通过环境变量 RABBITMQ_CLI_ALIASES_FILE 指定的文件地址来配置。 设置环境变量 RABBITMQ_CLI_ALIASES_FILE 的值： export RABBITMQ_CLI_ALIASES_FILE=/path/to/cli_aliases.conf cli_aliases.conf 文件内容如下： env = environment st = status --quiet lp = list_parameters --quiet lq = list_queues --quiet lu = list_users --quiet cs = cipher_suites --openssl-format --quiet 像上述这样设置后 rabbitmqctl env 相当于 rabbitmqctl environmentrabbitmqctl lq 相当于 rabbitmqctl list_queues --quietrabbitmq-diagnostics cs 相当于 rabbitmq-diagnostics cipher_suites --openssl-format --quiet]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高可用队列 - mirrored queue]]></title>
    <url>%2F2019%2F06%2F11%2F%E9%AB%98%E5%8F%AF%E7%94%A8%E9%98%9F%E5%88%97-mirrored-queue%2F</url>
    <content type="text"><![CDATA[1 queue mirror 介绍默认情况下，在RabbitMQ集群中，所有的信息，状态都会每个节点之间进行复制。但是队列例外，尽管在每个节点都可以看到并且可以访问所有队列，但是每个队列只会将其内容存储一个节点(定义队列的节点)上，如果想要队列内容存储也实现集群，则可以通过设置为mirrored queue实现跨多个节点。 每个mirrored queue都是由一个 master 节点和一到多个 mirror 节点， 每个 mirrored queue 都有自己的 master 节点，该队列的所有的操作都是在 master 节点上完成的 (包括生产者推送消息、分发消息到队列、消费者 ack 确认等操作)， master 节点之后再广播通知所有的 mirror 节点。消费者总是会连接到其对应 mirrored queue 的 master 节点上，即使连接的是 mirror 节点也会被转接到 master 节点，消费者 ack 确认后会通知 master 节点，然后会通知所有 mirror 节点，mirror 节点收到通知后会将已经ack的消息从队列删。mirrored queue保证了队列的高可用性 2 如何设置 mirrored queue通过设置队列的参数可以保证该队列是 mirrored queue，这些队列参数只能通过 Policies 来控制。普通队列可以随时变为 mirrored queue，反之亦然，只需要修改 Policies 即可。普通队列和有镜像的队列的不同之处在于：前者缺乏相关的参数，会有较高的吞吐量 具体的参数设置 设置 mirrored queue需要两个关键的参数 ha-mode 和 ha-param，其中 ha-param 是可选配置，这两个参数是相互呼应的。ha-mode 参数有三个值：exactly、all、nodes，且 ha-params 参数具体值为： count 和 node names 当 ha-mode 值为 exactly 时，ha-params 参数值是 count 也就是具体的数字，表示在队列集群中所有节点的数目(master + mirrors) 如果 count 值为1，说明集群中只有一个 master 节点，如果该节点故障，将会出现不可预测的结果 如果 count 值为2，说明集群中有两个节点，一个 master，一个 mirrors，如果 master故障，则 mirrors 节点会立刻取代成为master 如果集群中的节点数目比 count 的值小，则会使用全部的节点 如果集群中的节点比 count 的值大，则如果此时集群中的一个节点下线了，则会立刻加入新的节点进来 当 ha-mode 值为 all 时，此时无需设置 ha-params 参数。表示 mirrired queue 会将所有节点都会用到集群中，如果新增了一个节点也会被添加到集群中。这种方式是比较老旧的方式，会对网络I/O、磁盘I/O以及磁盘空间的利用率带来额外的负担，不应该将所有的节点都纳入集群中，官方推荐的集群中的节点数是 N/2 + 1 当 ha-mode 值为 nodes 时， ha-params 参数设置为 nodes names，具体的值是 rabbitmqctl cluster_status 命令查询出来的nodes的值，形如 rabbit@hostname 集群中多少节点比较合适 将所有的节点都应用到队列集群中，会对网络I/O、磁盘I/O以及磁盘空间的利用率带来额外的负担。如果节点数量是3个或3个以上，则推荐使用公司 (N+1)/2 计算需要放入集群中的节点数目。如果一些数据是瞬时态的或者对时间要求比较高，可以对这些队列降低节点数量，或者甚至不适用 mirrored queue 如何查看一个队列是否是mirrored queue 可以通过 WEB UI 页面查看相应的队列是否是存在集群，存在集群的队列形式如下： 3 mirrored queue的 master、master节点迁移、数据存放 集群中的master节点 集群中 master 节点的选举有是三种策略控制方式： 使用队列参数 x-queue-master-locator 通过 policy 设置 queue-master-locator 在配置文件中设置 queue_master_locator 上述三种配置方式可以达到相同的效果，配置的值是一样的，有以下几种情况： 设置值为 min-masters：选举节点中负载最小的为 master 设置值为 client-local:选举客户端定义队列时指定的节点为 master 设置值为 random：随机挑选一个节点 “nodes” 类型的mirrored queue 如果一个mirrored queue的 ha-mode设置为 nodes，则当更新该队列对应的 policy 时，如果当前的 master 节点没有在修改后的 ha-params指定的主机中，则该 master 节点会在当前集群中丢失。为了防止数据的丢失，RabbitMQ会保持 master 节点在线，直到所有的 mirrors 节点同步完成，该节点才会消失 独立队列 exclusive=true 集群 如果一个队列是独立性质的，即 exclusive=true，则该队列不能设置为 mirrored queue 普通队列集群 如果队列集群中的 master 节点正常运行，那么对于该队列的所有的操作都可以映射到集群中的每个节点上，该队列的操作仍然只会被路由到主节点。如果集群中的 master 节点故障了，那么该队列是否是持久化队列表现不同。非持久化队列直接删除，持久化队列的所有的操作都不能继续进行，直到节点恢复正常。这个时候在RabbitMQ的日志文件中可以看到相关报错信息，大致像这样： operation queue.declare caused a channel exception not_found: home node &apos;rabbit@hostname&apos; of durable queue &apos;queue-name&apos; in vhost]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[参数和Policies]]></title>
    <url>%2F2019%2F06%2F10%2F%E5%8F%82%E6%95%B0%E5%92%8CPolicies%2F</url>
    <content type="text"><![CDATA[前言RabbitMQ中的队列和交换器，除了一些必须属性 (eg：durable、exclusive等) 外，还有一些可选的参数。 这些参数的形式都是 x-argument，可以在队列或者交换器定义的时候通过Map类型的参数指定，这些参数可以赋予队列或者交换器一些其他的特征 通过定义队列或交换器的时候指定具体的参数，这可能在某些情况下是个不错的选择。 但是，这种控制方式有一些缺点： 不能灵活的对参数进行增删改查操作 一次只能为一个队列或者交换器指定参数，不能一次性为多个队列或交换器设置参数 在这种情况下，RabbitMQ引入了 Policies 介绍 PoliciesPolicies 的主要的属性： name：名称，可以是除基于ASCII的名称以外的任何名称，不建议使用空格 pattern：正则表达式，匹配队列或者交换器 definition：定义一系列的键值对，也就是参数，会注入到对应的队列和交换器中 priority：优先级 Policies 会自动的通过其 pattern 属性匹配到对应的队列或交换器，并且将其 definition 属性定义的参数注入到匹配到的队列或交换器中。 Policies 可以仅仅匹配队列、也可以仅仅匹配交换器，甚至可以两者同时匹配，这要取决于其 apply-to 指定的类型(queues、exchanges、all) ，默认的值是all。 每个队列或者交换器最多只能匹配有一个 Policies。 当更新 Policies 中相关的参数时，相关的队列或者交换器也会立即更新，对于比较繁忙的队列可能需要花费一点事时间。 当队列或者交换器每次创建的时候都会进行 Policies 的匹配和使用，不只是当 Policies 创建的时候 创建Policies 使用 rabbitmqctl 创建 Policies rabbitmqctl set_policy policies_name &quot;^amq\.&quot; &apos;{&quot;federation-upstream-set&quot;:&quot;all&quot;}&apos; --priority 1 --apply-to exchanges 使用 WEB UI 创建 Policies：Admin &gt; Policies &gt; Add/update a policy Operator Policies有时我们可能会希望可以强制控制一个 policies 的某些参数，但同时不影响其他的参数的设置，这个时候就可以同时使用 Operator Policies。 一个队列可以同时匹配一个普通的 policies 和一个 Operator Policies。 但是并不是每个参数都可以强制设定，Operator Policies 只允许下列参数设置： expires：设置队列超时时间 message-ttl：设置消息超时时间 max-length：队列中未分发的最大消息数目 max-length-bytes overflow 如果一个队列同时匹配了一个普通的 policies 和一个 Operator Policies，并且存在上述几个参数的设置冲突，则会选用两者中较小的那个值，因此，Operator Policies 不是覆盖普通 policies 的对应参数，而是在强制的同时尽量的不影响普通的 policies 定义 Operator Policies 使用 rabbitmqctl 创建 rabbitmqctl set_operator_policy transient-queue-ttl &quot;^amq\.&quot; &apos;{&quot;expires&quot;:1800000}&apos; --priority 1 --apply-to queues 使用 WEB UI 页面创建： admin &gt; Polocies &gt; Add / update an operator policy]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Virtual Hosts]]></title>
    <url>%2F2019%2F06%2F10%2FVirtual-Hosts%2F</url>
    <content type="text"><![CDATA[介绍vhosts在RabbitMQ中，virtual hosts 提供了逻辑上的资源隔离，这些资源包括连接、交换器、队列、 绑定、用户权限、策略等等都属于vhosts。 可以这样认为，用户在使用RabbitMQ的时候，所有的操作都是在vhosts下完成的，如果没有指定vhost则使用默认的vhost: / 创建virtual host可以使用 rabbitmqctl 或者 HTTP API。 当创建了一个vhost后如果用户想要使用这个vhost，则需要授予该用户相应的权限，默认新用户是没有任何权限的。 创建vhost 使用命令行创建。 创建一个名为 vhost_name 的vhost rabbitmqctl add_vhost [vhost_name] 使用 HTTP API。 调用 PUT /api/vhosts/{name} 接口添加vhost curl -u userename:pa$sw0rD -X PUT http://rabbitmq.local:15672/api/vhosts/vh1 设置vhost的最大连接数和最大创建队列数 设置vhost的最大连接数 设置为正整数，控制最大连接数目 rabbitmqctl set_vhost_limits -p vhost_name &apos;{&quot;max-connections&quot;: 256}&apos; 设置最大连接数为 0，禁止连接到该vhost rabbitmqctl set_vhost_limits -p vhost_name &apos;{&quot;max-connections&quot;: 0}&apos; 设置最大值为负数，不限制最大连接数 rabbitmqctl set_vhost_limits -p vhost_name &apos;{&quot;max-connections&quot;: -1}&apos; 设置vhost的最大队列数目 rabbitmqctl set_vhost_limits -p vhost_name &apos;{&quot;max-queues&quot;: 1024}&apos; rabbitmqctl set_vhost_limits -p vhost_name &apos;{&quot;max-queues&quot;: -1}&apos; 通过 WEB UI 页面操作vhost 创建vhost：【admin】 -&gt; 【Virtual Hosts】 授权用户操作vhost的权限：【admin】 -&gt; 【Virtual Hosts】 -&gt; 【点击某个vhost】 设置vhost的最大连接数和最大队列数目：【admin】 -&gt; 【Limits】 代码中vhost的使用代码中可以通过设置 connectionFactory 的virtual host来指定vhost，如果没有设置默认使用默认的vhsot： / public static Connection getConnection() throws Exception { ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost(HostConstant.HOST_NAME); connectionFactory.setUsername(HostConstant.USERNAME); connectionFactory.setPassword(HostConstant.PASSWORD); connectionFactory.setVirtualHost(&quot;vhost_name&quot;); return connectionFactory.newConnection(); }]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【备用】交换器]]></title>
    <url>%2F2019%2F06%2F06%2F%E3%80%90%E5%A4%87%E7%94%A8%E3%80%91%E4%BA%A4%E6%8D%A2%E5%99%A8%2F</url>
    <content type="text"><![CDATA[概述 有时我们可能会希望有客户端处理不能被路由的消息 (对应的RK没有消费者或者broker找不到对应的RK)，作用大致有： 监控客户端刻意或者偶尔发送的无法路由的消息，便于后续处理 特殊消息需要特殊处理 “备用”交换器 Alternate Exhcange，简称AE，就是用于处理这种情况下的一种交换器 AE跟之前我们学过的普通的交换器一样，唯一的区别或许就是：普通交换器接收的消息是客户端直接推送的，而AE接收的消息是经过另一个交换器转发来的。 如果某个交换器配置了AE，则当某个消息无法路由到指定的队列的时候，就会尝试推送到配置的AE，如果AE仍无法路由，则会推送到AE配置的另一个AE，如此循环下去，直到消息能够被消费。 当然，如果消息最终还是未能路由，那么该消息就丢失了 配置AE 配置一个交换器的AE有两种方式 定义交换器时通过配置参数 alternate-exchange ... Map&lt;String, Object&gt; exchangeArgs = new HashMap&lt;&gt;(1); exchangeArgs.put(&quot;alternate-exchange&quot;, ALTERNATE_EXCHANGE_NAME); channel.exchangeDeclare(BUSINESS_EXCHANGE_NAME, BuiltinExchangeType.DIRECT, false, false, exchangeArgs); ... 使用 policies rabbitmqctl set_policy AE &quot;^my-direct$&quot; &apos;{&quot;alternate-exchange&quot;:&quot;my-ae&quot;}&apos; 具体示例代码 生产者程序 ... try (Connection connection = MQUtil.getConnection(); Channel channel = connection.createChannel()) { for (int i = 1; i &lt;= 8; i++) { String message = &quot;NO.&quot; + i; channel.basicPublish(BUSINESS_EXCHANGE_NAME, RK2, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes()); System.out.println(String.format(&quot;发送消息:[%s]成功&quot;, message)); } } ... 运行结果 发送消息:[NO.1]成功 发送消息:[NO.2]成功 发送消息:[NO.3]成功 发送消息:[NO.4]成功 发送消息:[NO.5]成功 发送消息:[NO.6]成功 发送消息:[NO.7]成功 发送消息:[NO.8]成功 业务消费者 channel.queueBind(QUEUE_NAME, BUSINESS_EXCHANGE_NAME, RK); AE消费者 ... channel.exchangeDeclare(ALTERNATE_EXCHANGE_NAME, BuiltinExchangeType.FANOUT); String queueName = channel.queueDeclare().getQueue(); channel.queueBind(queueName, ALTERNATE_EXCHANGE_NAME, &quot;&quot;); channel.basicConsume(queueName, new DefaultConsumer(channel) { @Override public void handleConsumeOk(String consumerTag) { super.handleConsumeOk(consumerTag); System.out.println(&quot;准备接收alternative消息...&quot;); } @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { String message = new String(body); channel.basicAck(envelope.getDeliveryTag(), false); System.out.println(String.format(&quot;收到消息：[%s]&quot;, message)); } }); ... 运行结果 准备接收alternative消息... 收到消息：[NO.1] 收到消息：[NO.2] 收到消息：[NO.3] 收到消息：[NO.4] 收到消息：[NO.5] 收到消息：[NO.6] 收到消息：[NO.7] 收到消息：[NO.8] 程序中定义了一个AE名称为 ALTERNATE_EXCHANGE_NAME，类型为 fanout。业务消费者使用的是 RK，生产者使用的 RK2 因此无法路由到任何的队列中，这时消息就会推送到AE，进而进入到对应的AE绑定的队列中，最后被消费]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[队列懒加载]]></title>
    <url>%2F2019%2F06%2F06%2F%E9%98%9F%E5%88%97%E6%87%92%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[队列懒加载RabbitMQ从3.6.0 版本开始，RabbitMQ引入了懒加载队列的概念 RAM内存警报 默认情况下，RabbitMQ会时实时监控该服务使用内存的情况，当使用的内存超过服务所在计算机的总RAM内存的40%时，就会触发内存警报，此时RabbitMQ就会阻塞所有正在推送消息的连接直到内存警报解除。 出现内存警报时， RabbitMQ会将消息尽量的移出到硬盘上来解决RAM内存占用过多问题。 你可以通过修改配置文件来更改默认的阀值，默认是0.4，即 40% vm_memory_high_watermark.relative = 0.4 当然，你也可以设置一个绝对的值，单位是：byte vm_memory_high_watermark.absolute = 1073741824 内存阀值也可以在broker运行期间通过命令行设置进行更改： rabbitmqctl set_vm_memory_high_watermark [fraction]：设置相对值 rabbitmqctl set_vm_memory_high_watermark absolute [memory_limit]：设置绝对值 如果想要立刻解决内存警报，全局停止所有的消息传送，那么可以设置内存阀值为 0 rabbitmqctl set_vm_memory_high_watermark 0 缩减RAM占用 为了解决RAM内存占用过多的问题，RabbitMQ在内存占用达到上述设置的内存阀值的50%的时候，就会开始将消息内容从队列中移出到硬盘保存的工作 (持久化消息在接收的时候就已经保存到硬盘，此时会清除持久化消息在RAM内存中的副本)。 这个阀值也可以配置文件修改，默认值是0.5： vm_memory_high_watermark_paging_ratio = 0.75 该值也可以设置为一个大于 1 的数值，这时该值就不会起作用 设置队列懒加载 队列有两种形式：默认模式 default 和懒加载模式 lazy。默认模式下，当队列收到消息的时候会将消息存放到RAM内存中 (如果是持久化队列，则会在磁盘和内存中各有一份) ，这就保证了消息最快的被分发到消费者。懒加载模式下，队列会试图尽可能早的将消息从RAM移出到磁盘中，这样就会释放了RAM内存，带来的代价就是I/O的开销。 队列的懒加载模式可以通过两种形式设置 使用 policy 设置, 可以通过命令行，也可以通过 WEB UI 页面进行操作 rabbitmqctl set_policy Lazy &quot;^lazy-queue$&quot; &apos;{&quot;queue-mode&quot;:&quot;lazy&quot;}&apos; --apply-to queues 通过队列参数设置 x-queue-mode Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(); args.put(&quot;x-queue-mode&quot;, &quot;lazy&quot;); channel.queueDeclare(&quot;myqueue&quot;, false, false, false, args); 运行时队列模式切换 当一个队列从 default 模式切换到 lazy 模式时，该队列会将所有存在RAM中的消息移出到磁盘上，与此同时，该队列将不会接收任何新的推送消息，直到模式转换操作完成，所有的操作才能正常进行 当一个队列从 lazy 模式切换到 default 模式时，相当于重启服务后的队列恢复操作，该队列中将会把最多 16384 条消息加载到内存中 关于延迟队列的一些说明 当将节点内存使用率保持在较低的优先级，并且可以接受较高的磁盘I/O和磁盘使用率时，可以考虑使用延迟队列 当一个RabbitMQ节点正在运行并且正常操作的情况下，延迟队列会保证除了正在传送中的信息，其他的信息都会存放在磁盘上 如果一个RabbitMQ节点所在的主机不能充分提供需要的内存和磁盘空间，那么该节点是无法正常启动的 如果一个RabbitMQ节点受内存限制，或者在该主机上又很多的延迟队列，那么这将会规划容量很重要的考虑因素 当一个RabbitMQ节点启动时，所有的队列(包括延迟队列)将会最多将队列中 16384 条消息加载到内存中]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优先级队列]]></title>
    <url>%2F2019%2F06%2F06%2F%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[优先级队列从 3.5.0 版本开始，RabbitMQ提供了优先级队列的实现。如果要实现优先级队列需要两部操作即可： 通过队列参数定义具有优先级性质的队列 Map&lt;String, Object&gt; arguments = new HashMap&lt;String, Object&gt;(); arguments.put(&quot;x-max-priority&quot;, 10); channel.queueDeclare(queueName, true, false, true, arguments); 通过设置队列参数 x-max-priority 设置队列的优先级，队列的优先级支持 0~255 的数值，推荐使用的范围是： 1~10。 该属性设置的是该队列中的消息允许的 最大优先级数值，不支持使用 policy 设置，因为 policy 是可以随时更新改变的。 生产者推送消息的时候设置 AMQP.BasicProperties 的 priority 为该消息具体的优先级数值 String[] messageAry = {&quot;hello&quot;, &quot;world&quot;, &quot;test&quot;}; for (String message : messageAry) { AMQP.BasicProperties.Builder basicPropertiesBuilder = new AMQP.BasicProperties().builder(); if (&quot;test&quot;.equalsIgnoreCase(message)) { basicPropertiesBuilder.priority(6); } channel.basicPublish(EXCHANGE_NAME, ROUTING_KEY, basicPropertiesBuilder.build(), message.getBytes()); System.out.println(String.format(&quot;send message[%s] over&quot;, message)); } 该数值范围为 0~255 默认不设置的时候是 0。 如果超过对应的队列中 x-max-priority 设置的最大值，则会被强制设置为 x-max-priority 指定的最大值 使用优先级队列，你可能需要关注这些 使用优先级队列，会存在内存、磁盘以及CPU的额外消耗，设置的优先级越高，消耗越大 如果消费者消费能力很强，可能不会有队列对其中的消息进行优先级排序的时间，那么这个时候或许结果看起来，设置的优先级并没有起到作用。 因此，通常会使用 channel.basicQos(1) 设置 prefetch 当优先级和TTL同时使用时，可能会造成低优先级的已过期消息会被阻塞在高优先级未过期的消息后面，这些已过期的消息不会被传递给消费者，并且会计入队列的统计数据中 当优先级和队列最大限制一起使用时，可能会造成当队列达到最大限制时，还未消费的高优先级的消息被移除丢弃]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[队列的长度限制]]></title>
    <url>%2F2019%2F06%2F06%2F%E9%98%9F%E5%88%97%E7%9A%84%E9%95%BF%E5%BA%A6%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[队列的长度限制队列可以被设置大小，包括：队列中最大容纳的消息数目以及队列中容纳消息的最大总字节数。这两个值可以通过队列的参数 (x-max-length 和 x-max-length-bytes) 以及 policy (max-length 和 max-length-bytes) 来设置。 max-length | x-max-length 表示队列中容纳的最多消息个数 max-length-bytes | x-max-length-bytes 表示队列中的消息最大总字节数 默认情况下，当设置了容量的队列中的消息达到了设置的最大容量值后，队列会将处于队列前面的那些消息(也就是比较旧的消息) 移除或者放入”死信队列”。如果需要改变这种溢出处理策略，则可以通过队列参数 overflow 或者 x-overflow 进行修改。 overflow | x-overflow 定义队列溢出后数据处理策略 该参数有两个值 drop-head 和 reject-publish，默认是 drop-head。 如果被设置为 reject-publish 则如果收到新消息，则会直接拒绝并丢弃。如果这时生产者使用了 publish confirm 模式，则生产者会收到 nack 通知。 当一个生产者对应有多个消费者，如果其中一个消费者对应的队列满了，并且设置了 overflow=reject-publish，则生产者会收到 nack 通知。需要注意的是：如果设置了溢出策略为 reject-publish 则被丢弃的消息不会进入对应的 “死信交换器” 生产者程序：生产者连续推送8条消息到broker ... for (int i = 1; i &lt;= 8; i++) { String message = &quot;NO.&quot; + i; channel.basicPublish(BUSINESS_EXCHANGE_NAME, RK, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes()); System.out.println(String.format(&quot;发送消息:[%s]成功&quot;, message)); } ... 业务消费者程序 ... channel.basicQos(1); Map&lt;String, Object&gt; queueArgs = new HashMap&lt;&gt;(2); queueArgs.put(&quot;x-dead-letter-exchange&quot;, DEAD_LETTER_EXCHANGE_NAME); queueArgs.put(&quot;x-max-length&quot;, 2); channel.queueDeclare(QUEUE_NAME, false, false, true, queueArgs); channel.queueBind(QUEUE_NAME, BUSINESS_EXCHANGE_NAME, RK); // 消费消息 channel.basicConsume(QUEUE_NAME, false, new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { String message = new String(body); long deliveryTag = envelope.getDeliveryTag(); try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } channel.basicAck(deliveryTag, false); System.out.println(String.format(&quot;消费消息:[%s]，手动确认ack&quot;, message)); } }); ... 消费者设置 prefetch 为1，即 ack 确认前该消费者不能再接收消息， 并且收到消息后会sleep 3s的时间，为了让队列中能够累积消息 运行结果 业务消费者 消费消息:[NO.1]，手动确认ack 消费消息:[NO.7]，手动确认ack 消费消息:[NO.8]，手动确认ack “死信”消息消费者 收到死信消息：[NO.2]，手动回复ack 收到死信消息：[NO.3]，手动回复ack 收到死信消息：[NO.4]，手动回复ack 收到死信消息：[NO.5]，手动回复ack 收到死信消息：[NO.6]，手动回复ack 从程序运行结果中可以看出，当消费者消费了第一条消息后，由于sleep 3s 的原因，这时队列中的消息产生了堆积。 由于设置了 x-max-length 为 2，因此队列中只存了两条最新的消息 NO.7 和 NO.8，且 NO.2~NO.6 都变成了 “死信” 消息， 转发到了 “死信” 交换器 DEAD_LETTER_EXCHANGE_NAME 需要关注的部分 需要通过 channel.basicQos() 方法设置一个合适的 prefetch 限制每个消费者在 ack 之前可以最多收到的消息数目。 如果没有设置，那么broker总会将队列中的消息立刻转发到对应的客户端，此时 x-max-length 的设置也就没有了意义 如果更改了队列溢出策略 overflow 为 reject-publish 则超出限制的消息不会被 “死信”]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【死信】交换器]]></title>
    <url>%2F2019%2F06%2F05%2F%E3%80%90%E6%AD%BB%E4%BF%A1%E3%80%91%E4%BA%A4%E6%8D%A2%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1 “死信”交换器介绍“死信”交换器跟普通的各种类型的交换器是一样的，你完全可以像定义普通交换器那样定义它。 当消息变为”死信”的时候，就会被转发到设置的对应的”死信”交换器上。 那么消息在什么情况下会变成”死信”呢？ 当消息被消费者使用 basic.reject 或者 basic.nack 拒绝，并且 requeue 参数设置为 false, 即被拒绝但是要求不要重新入队的消息。 注意：这种情况下一定要设置 auto-delete 为false 消息由于设置了TTL导致过期，这种情况下消息变为”死信”消息后，其原来的过期属性 expiration 会被移除，防止再次过期 消息对应的队列设置了队列大小限制，超过限制被丢弃的消息。 这种情况下，overflow 参数必须是默认的 drop-head 超出限制的消息才会被认为是”死信”消息，进而被推送到”死信”交换器上；如果设置为 reject-public 则不会被认为是”死信”消息 请注意：当为队列设置了TTL时间，队列过期了，但是里面的消息并不会被看做”死信”消息 2 “死信”交换器的设置2.1 创建”死信”交换器“死信”交换器可以使用RabbitMQ的 WEB UI 控制台进行添加。 当然，你仍然可以像创建普通交换器那样，在代码创建”死信”交换器 2.2 “死信”交换器的设置可以通过设置队列的相应参数来控制该队列中”死信”消息需要转发到的具体的”死信”交换器，设置参数的方法有两种：通过定义队列是设置队列参数以及通过 policies 来控制 使用 policies 来控制 设置 dead-letter-exchange 属性，指定具体的”死信”交换器。 也可以设置 dead-letter-routing-key 属性来控制推送消息到指定的”死信”队列时使用的 RoutingKey，如果没有设置，则默认会使用该消息本身已经拥有的 RoutingKey 来路由消息 rabbitmqctl set_policy DLX &quot;.*&quot; &apos;{&quot;dead-letter-exchange&quot;:&quot;my-dlx&quot;}&apos; --apply-to queues 使用队列参数控制 定义队列时使用队列参数定义：设置 x-dead-letter-exchange 和 x-dead-letter-routing-key 参数。 Map&lt;String, Object&gt; queueArgs = new HashMap&lt;&gt;(4); queueArgs.put(&quot;x-dead-letter-exchange&quot;, &quot;dead.letter.test.yb&quot;); channel.queueDeclare(QUEUE_NAME, false, false, false, queueArgs); “死信”消息 – 消费者拒绝消息且要求不重新入队 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; { channel.basicReject(delivery.getEnvelope().getDeliveryTag(), false); }; “死信”消息 – TTL消息超时： 如果消息在队列中3s之内不能分发到对应的消费者，则该消息就会超时被转发到”死信”交换器 AMQP.BasicProperties basicProperties = new AMQP.BasicProperties() .builder() .expiration(&quot;3000&quot;) .build(); channel.basicPublish(EXCHANGE_NAME, &quot;RK-DEAD-LETTER-001&quot;, basicProperties, message.getBytes()); “死信”消息 – 队列消息超限： 队列中如果已经含有2条消息未分发到消费者，则当新消息进来时就会将原来的消息依次丢弃进入对应的”死信”交换器。 注意：overflow参数必须保证为默认的 drop-head，否则将不会变为 “死信” 消息 Map&lt;String, Object&gt; queueArgs = new HashMap&lt;&gt;(4); queueArgs.put(&quot;x-max-length&quot;, 2); // 最多容纳2条未消费的消息 channel.queueDeclare(QUEUE_NAME, false, false, false, queueArgs); 当该队列中的消息发生”死信” (消息被拒绝、消息在队列中超时、消息数量超限被丢弃) 时，该消息会通过其原来的 RoutingKey (或者 x-dead-letter-routing-key 参数指定的值) 推送到 dead.letter.test.yb 交换器，进而推送到对应的消费队列中 3 “死信”消息的 headers“死信”消息的 headers 中法跟其他消息有所不同，其 headers 如下： { x-first-death-exchange=test-dead-exchange, x-first-death-reason=expired, x-first-death-queue=test-dead-queue-001, x-death=[{ reason=expired, original-expiration=3000, count=1, exchange=test-dead-exchange, time=Wed Jun 05 15:24:12 CST 2019, routing-keys=[RK-DEAD-LETTER-001], queue=test-dead-queue-001} ] } “死信”消息会在 headers 中添加一个名为 x-death 的数组，数组中的key字段意义大致如下： reason：成为”死信”消息的原因，其值有：expired、rejected、maxlen original-expiration: 该消息原来定义的超时时间 count：该消息在当前这个队列中由于当前这个原因被”死信”的次数 exchange：该消息原来所在的交换器 time：成为”死信”消息的时间 routing-keys：该消息对应的RK queue：该消息原来所在的队列 除此之外，还增加有 x-first-death-exchange，x-first-death-reason 和 x-first-death-queue 三个属性，从命名上就可以知道，这三个标识的是该消息首次成为”死信”消息对应的 x-death 中的 exchange，reason，queue三个值，不同的是这三个值后续不会再改变。 当成为”死信”消息到达对应的”死信”队列后，如果记录进行处理推送，如果再次变成”死信”则 x-death 字段中就会有多个对象出现，count 值就会相应增加]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TTL和过期时间]]></title>
    <url>%2F2019%2F06%2F04%2FTTL%E5%92%8C%E8%BF%87%E6%9C%9F%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[1 TTL介绍TTL全称Time-To-Live，即存活时间。在RabbitMQ中有两种TTL，分别是 Message TTL 和 Queue TTL。TTL可以通过参数设置，也可以通过 policies 策略设置 message-ttl 参数，推荐使用 policies 可以通过正则表达式为一个或者多个 queue 或者 exchange 定义TTL 2 Message TTL – TTL类型消息如果一条消息在队列中的存放时间超过了设置的TTL超时时间 （即在TTL设置的时间内没有消费者消费该消息），则该消息就会被认为已经”死了”，broker不会将”死了”的消息再推送给消费者，并且将会移除这些消息。消息超时时间必须是一个非负整数(&gt;=0)，单位是：毫秒 定义消息的TTL分为两种方式： 在队列中定义以及在消息中定义 在队列中定义，设置的TTL值只对当前队列的消费者有效 通过 channel.queueDeclare 方法，其最后一个参数 arguments 中添加 x-message-ttl 字段，其值设置为具体的超时时间即可。例如，设置消息超时时间为3s，则部分代码如下： Map&lt;String, Object&gt; arguments = new HashMap&lt;&gt;(); arguments.put(&quot;x-message-ttl&quot;, 3000); channel.queueDeclare(queueName, true, false, false, arguments); 使用 policies 设置时，会选择 apply-to=queues，因此也属于该种方式 在消息中定义，设置的TTL值对该消息的所有的消费者都有效 也可以通过生产者调用 basic.publish 方法，设置 AMQP.BasicProperties 参数的 expiration 属性。例如： AMQP.BasicProperties basicProperties = new AMQP.BasicProperties() .builder() .expiration(&quot;3000&quot;) .build(); channel.basicPublish(EXCHANGE_NAME, ROUTING_KEY, basicProperties, message.getBytes()); 使用TTL时，你可能有些地方需要注意 发送设置了TTL的消息到队列中时，如果此时队列中已经有了其他设置了TTL的消息，有可能会出现队列中已经过期的消息在未过期消息的后面。这种情况下该已过期的消息不会被移除，只有当其前面的消息过期或者被消费者消费掉，该过期消息到达队列头部时才会被丢弃(或者放入”死信”队列)。并且，该已过期的消息在未被移除之前，其占用的系统资源并不会释放，该消息仍然会被计入到一些统计数据中(eg: 队列中总消息数目)。 设置TTL的消息会存在一种情况：已经被broker写入socket向消费者传送，但是在到达消费者之前，过期了（这种情况下，笔者也不知消息将会怎样？） 当使用 policy 设置TTL时，建议有消费者实时在线消费消息，以确保过期的消息能够尽快的被丢弃 考虑到上述行为，当需要删除消息释放资源的时候，设置了TTL的队列queue TTL应该考虑使用 3 Queue TTL – TTL类型队列TTL不仅能设置到队列中的消息上，还能设置到队列上。设置到队列上表示的意义是：在该队列自动删除之前还能存留的时间，单位是：毫秒，必须是正整数(&gt;0), ，设置了TTL的队列，当没有消费者后，等待超时时间后就会被删除，跟队列的 auto-delete 属性无关。 使用队列属性参数定义。 如下，定义一个TTL为5s的队列： Map&lt;String, Object&gt; arguments = new HashMap&lt;&gt;(); arguments.put(&quot;x-expires&quot;, 5000); // 设置队列过期时间 channel.queueDeclare(QUEUE_NAME, true, false, false, arguments); 当该队列没有消费者后，等待5s就会被删除，即使 autoDelte 参数为false 使用 policy 定义 设置 policy 策略的 expires 参数，可以达到和 x-expires 一样的效果，更推荐使用 policy 定义。如： rabbitmqctl set_policy expiry &quot;.*&quot; &apos;{&quot;expires&quot;:5000}&apos; --apply-to queues 语法格式：rabbitmqctl set_policy &lt;policy名称&gt; &lt;JSON格式参数&gt; –apply-to [queues|exchanges]。除了使用命令行，也可以在WEB UI上直接定义设置 policy]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Topic交换器]]></title>
    <url>%2F2019%2F06%2F03%2FTopic%E4%BA%A4%E6%8D%A2%E5%99%A8%2F</url>
    <content type="text"><![CDATA[上次文章说到 Fanout交换器，有兴趣的可以参考：Fanout交换器 1 应用场景当需要“分类”推送消息的时候，就会用到 topic 类型的交换器。例如：推送日志信息，需要将系统日志和普通日志分类推送给不同的队列；当然使用前面说到的 direct 类型交换器和 fanout交换器也可以实现，但是比较麻烦，这种场景下，topic 类型交换器将是你最好的选择。 2 Topic交换器 topic 交换器允许使用带有”通配符”的 RoutingKey 将队列和broker绑定在一起，支持的通配符有两种：* 和 # * 匹配一个单词，以 . 为分割标记。例如： *.rabbit 可以代表 one.rabbit 、two.rabbit等等 # 匹配一个或者多个单词 2.1 生产者推送消息// 创建交换器：auto-delete=false durable=false channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC, true); // 发送消息 String message = &quot;hello topic exchange&quot;; String routingKey = &quot;TOPIC.RK.001&quot;; channel.basicPublish(EXCHANGE_NAME, routingKey, null, message.getBytes()); 生产者推送消息到broker，可以看到使用的 RoutingKey 是 TOPIC.RK.001 2.2 消费者消费消息，这里定义两个消费者 Recv1 和 Recv2Recv1.java 部分代码如下： // 创建交换器 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC, true); // 创建一个私有的临时的队列 exclusive=true auto-delete=true durable=false String queueName = channel.queueDeclare().getQueue(); // 绑定队列和broker channel.queueBind(queueName, EXCHANGE_NAME, &quot;TOPIC.*.*&quot;); Recv2.java 部分代码如下： // 创建交换器 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC, true); // 创建一个私有的临时的队列 String queueName = channel.queueDeclare().getQueue(); // 绑定队列和broker channel.queueBind(queueName, EXCHANGE_NAME, &quot;TOPIC.#&quot;); 以上可以看到，Recv1.java 中使用的 RoutingKey 是 TOPIC.*.*；而 Recv2.java 中使用的 RoutingKey 是 TOPIC.#。此时，当生产者程序启动向broker推送消息，则 Recv1 和 Recv2 都会接收到消息 如果生产者的 RoutingKey 换成 TOPIC.001 则 只有 Recv2 能接收到消息 如果生产者的 RoutingKey 换成 RK.001 则两者都不会接收到消息 3 总结 topic 交换器支持通配符匹配，支持的通配符有 * 和 # 当精准匹配的时候相当于 direcr 交换器 当模糊匹配的时候相当于 fanout 交换器]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fanout交换器]]></title>
    <url>%2F2019%2F05%2F27%2FFanout%E4%BA%A4%E6%8D%A2%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1 知识回顾通过之前 direct 交换器的学习，我们已经对rabbitMQ消息传递机制有了一定的了解，可以总结为以下几点： 生产者是生产并发送消息的应用程序 队列是消息的缓冲区，用来存放消息 消费者是接收并消费消息的应用程序 我们知道，broker是生产者和消费者之前的”桥梁”，接收生产者消息并将消息发送给消费者。那么，应该发给那些消费者，是指定的消费者还是全部的消费者呢？这就取决于 exchange 的类型，一共四种类型：direct，headers，fanout，topic，其中 headers 跟 direct 很类似，基本不再使用。 这里我们将会说到 fanout 交换器 2 应用场景生产者发送的消息到broker，所有绑定到改broker的队列对应的消费者都可以接收到消息，类似于”广播”通知模式。例如注册操作。 一般情况下，用户注册后都会进行一系列的业务操作，比如站内信通知，发送积分，甚至活动期间发送奖励等。这时，就需要当用户注册后，所有关注 “注册” 的业务都需要收到 “用户注册” 这个消息，并进行相应的逻辑处理，这时就可以用 fanout 类型交换器实现消息的推送通知。 3 进入正题 3.1 生产者发送消息// 定义Fanout类型的交换器 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT, true); // 发送消息 String message = &quot;hello world&quot;; channel.basicPublish(EXCHANGE_NAME, &quot;&quot;, null, message.getBytes(&quot;UTF-8&quot;)); System.out.println(String.format(&quot;推送消息[%s]成功&quot;, message)); 我们可以看到 basicPublish 方法的第二个参数 routinhKey 为 &quot;&quot;。这里无论是否使用空字符串，效果都是一样的，因此直接使用 &quot;&quot; 即可 3.2 消费者接收消息// 创建交换器 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT, true); // 创建一个私有的临时的队列 exclusive=true auto-delete=true durable=false String queueName = channel.queueDeclare().getQueue(); // 绑定队列到交换器 channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;); // 消费消息 channel.basicConsume(queueName, true, deliverCallback, consumerTag -&gt; {}); 当然，你完全可以像之前那样定义一个持久性有固定名称的队列。但是，如果有需要 （比如每次连接到broker都需要一个全新的队列），这时就可以使用方法 channel.queueDeclare() 创建一个随机的队列，该队列性质：exclusive=true，auto-delete=true，durable=false 这里还要说下 queueBind() 方法，可以看到该方法的第三个参数 routingKey 也是 &quot;&quot;。 就像我们之前说的那样，这里也是一样，无论是否使用空字符串效果都是一样的，因为 fanout 类型的交换器会把到达broker的消息发送给所有绑定到该交换器上的 queue 中 (无论使用的routingKey是否是””)]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Direct类型交换器-生产者confirm模式]]></title>
    <url>%2F2019%2F05%2F26%2FDirect%E7%B1%BB%E5%9E%8B%E4%BA%A4%E6%8D%A2%E5%99%A8-%E7%94%9F%E4%BA%A7%E8%80%85confirm%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Direct类型交换器-生产者confirm模式上篇文章简单入门了Direct交换器，如有需要请查看 Direct类型交换器-基础使用 1 prefetch属性的设置问题：分布式环境中，每个消费者会有多个实例同时存在，这时对应的生产者推送的消息，该消费者如何消费呢？是均匀的分发，还是根据消费能力，能者多劳呢？ 答案是：均匀分发消费。如果一个消费者有多个实例，那么到达这个消费者的消息会被broker进行均匀的分发消费，这是broker默认的机制。当然，实际应用中，会有很多的条件导致该消费者的多个实例的消费能力不同 (比如机器配置不同、网络带宽影响等等)，这时我们理想的情况是”能者多劳”。这时，我们只需要调用 basicQos 方法这时 prefetch = 1 即可 ，即可达到理想效果 (这也是springBoot集成rabbitMQ的默认配置)。这样设置的情况下，如果某个消费者实例消费能力比较弱，在收到 ack 确认之前，broker不会再分发消息到该实例 int prefetchCount = 1; channel.basicQos(prefetchCount); 2 生产者confirm模式上篇文章说到，消费者可以采用手动 ack 确认的模式尽量的防止消息的丢失。但是，这样真的就达到目的了吗？当然不是，试想，如果生产者的消息根本就没有到达broker呢？要解决这个问题，就需要用到生产者confirm模式 2.1 设置channel为confirm模式// 将信道设置为confirm模式 channel.confirmSelect(); broker如果接收到消息会进行回调，生产者有两种方式可以进行消息发送成功以及失败的后续处理，分别是手动逐条确认和异步监听确认 2.2 手动逐条确认每次发送消息后进行确认 if (channel.waitForConfirms()) { System.out.println(String.format(&quot;推送消息[%s]成功&quot;, message)); } else { System.out.println(String.format(&quot;推送消息[%s]失败，消息丢失&quot;, message)); } 2.3 异步监听确认还可以通过添加监听进行异步确认。改方式的优点是：异步、可以批量确认 channel.addConfirmListener(new ConfirmListener() { @Override public void handleAck(long deliveryTag, boolean multiple) throws IOException { System.out.println(String.format(&quot;MQ接收消息[%s:%b]成功&quot;, deliveryTag, multiple)); } @Override public void handleNack(long deliveryTag, boolean multiple) throws IOException { System.out.println(String.format(&quot;MQ接收消息[%s:%b]失败，消息丢失&quot;, deliveryTag, multiple)); } }); 我们来看下异步确认程序的执行结果： MQ接收消息[2:true]成功 MQ接收消息[3:false]成功 MQ接收消息[4:false]成功 MQ接收消息[5:false]成功 MQ接收消息[6:false]成功 从执行结果中可以看出，是否批量确认在于返回的multiple的参数，此参数为bool值。有时 multiple 返回的是 true，这说明批量确认了 响应的 deliveryTag 标识的该条消息之前的所有消息，返回 false 表示单条确认对应的 deliveryTag 这条消息。可以看到使用这种模式 deliveryTag 会从1依次递增标识消息。 3 总结 一般情况下消费者会使用 channel.basicQos(int prefetch) 方法设置prefetch为1，达到同个消费者多个实例之间”能者多劳”的目的 为了尽量的保证避免消息的丢失，应该同时采用消费者手动ack和生产者confirm模式 虽然rabbitMQ还有事务机制保证生产者发送的消息一定会到达broker，但是本身性能受损比较严重，不建议使用，有兴趣的可以另行查找资料 4 扩展Direct 类型交换器和队列的绑定是通过 RoutingKey 来完成的，RoutingKey 和 queue 的关系不只是一对一的关系，还可以是一对多，多对一关系。注：以下情况每个队列对应一个消费者 一对多模型，一个 RoutingKey 可以绑定多个不同的 queue （假设名称为q1，q2，q3） 到broker上，q1，q2，q3对应的消费者分别为 c1、c2和c3。这种情况下，如果生产者通过该 RoutingKey 发送消息，则c1、c2和c3都会收到相同的消息 多对一模型，多个不同的 RoutingKey （假设名称为rk1，rk2，rk3） 可以绑定同一个 queue 到broker上，该队列对应的消费者是 c1 。这种情况下，如果生产者通过rk1，rk2，rk3中的任意一个发送消息，则 c1 都会接收到消息]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Direct类型交换器-基础使用]]></title>
    <url>%2F2019%2F05%2F26%2FDirect%E7%B1%BB%E5%9E%8B%E4%BA%A4%E6%8D%A2%E5%99%A8-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Direct交换器-基础使用1 建立连接，获取信道MQUtil.java // 建立到代理服务器的连接 public static Connection getConnection(String vhost) throws Exception { ConnectionFactory connectionFactory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); factory.setUsername(&quot;admin&quot;); factory.setPassword(&quot;admin&quot;); if (!StringUtils.isEmpty(vhost)) { connectionFactory.setVirtualHost(vhost); } return connectionFactory.newConnection(); } 后续的动作都是用channel来完成，使用try-resource包装，使得connection和channel可以自动关闭 try (Connection connection = MQUtil.getConnection(); Channel channel = connection.createChannel()) {...} 2 生产者推送消息生产者推送消息到MQ只需要RoutingKey和Exchange即可： // 定义交换器. durable标识是否持久化 channel.exchangeDeclare(exchange, BuiltinExchangeType.DIRECT, durable); // 推送消息 channel.basicPublish(exchange, routingKey, props, body); 方法参数意义： exchange: 使用的交换器名称，如果使用默认的交换器，此处使用空字符串 &quot;&quot; routingKey: 消息指定的RoutingKey，MQ会通过该RoutingKey将消息分发到通过该值绑定的队列中 props: 该参数的类型是 BasicProperties 主要用来设置消息的一些信息，如contentType、headers等。 MessageProperties 是获取 BasicProperties 对象的一个工具类，只要用来获取不同类型的信息 body: 消息本身内容，类型是 byte[] 3 消费者消费消息3.1 定义交换器和队列消费消息时不需要将 Connection 和 Channel 进行 try-resource 封装，因为消费者需要循环的监控接收消息，因此不能关闭信道和连接 // 定义交换器 channel.exchangeDeclare(exchange, type, durable); // 定义队列 channel.queueDeclare(quueName, true, false, false, null); // 将队列通过RoutingKey绑定到交换器上 channel.queueBind(queue, exchange, routingKey); 这里主要看下 queueDeclare 方法，该方法的定义如下： Queue.DeclareOk queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete,Map&lt;String, Object&gt; arguments) throws IOException; queue: 队列名称 durable: 是否持久化 exclusive: 是否排他，如果设置为true，则表示只能用于创建其的连接中，不能用于另外的连接(例如：如果有两个客户端同时都是新创建连接，然后定义相同的一个 exclusive 属性为true的队列，则只有其中的一个能成功启动，另外一个启动会报错)。 并且，当连接关闭或者断开的时候，该队列会被自动删除 (即使定义的队列是持久化的) autoDelete: 是否自动删除。 如果设置为true，则当没有消费者使用这个队列的时候，这个队列会被自动删除 3.2 消费消息// 消费者成功接收到消息，消费回调函数 DeliverCallback deliverCallback = (consumerTag, message) -&gt; { String receiveMsg = new String(message.getBody()); // 手动确认消息的接收 channel.basicAck(message.getEnvelope().getDeliveryTag(), false); }; // 消费消息 channel.basicConsume(QUEUE_NAME, deliverCallback, (consumerTag) -&gt; { System.err.println(String.format(&quot;系统异常，消费者[%s]不能正常消费消息&quot;, consumerTag)); }); 需要注意的是 basicAck 方法的第二个参数，这个参数标识是否要批量确认。如果设置为 true 则会批量确认所有该channel中已经到达MQ服务器的消息；如果设置为 false，则只确认指定的deliverTag对应的消息。 再来看下消费消息的函数 basicConsume 定义如下： String basicConsume(String queue, DeliverCallback deliverCallback, CancelCallback cancelCallback) throws IOException; 该方法是一个无限循环阻塞方法，会循环获取绑定的队列中的消息 queue：队列名称。 指定消费者从哪个队列中消费消息 deliverCallback: 消费者成功接收MQ推送的消息的回调函数，主要在该函数中进行消息的处理以及手动ack。该函数有个重载，多了一个 autoAck 参数，标识是否自动确认消息的接收。如果设置为 true 则当消费者正常接收到消息就会向MQ自动确认，MQ就会将该消息从消息队列中删除(即使消息后续没有被成功消费)， 默认false，一般情况下都会使用默认false。 如果设置为 false 就需要在 deliverCallback 回调函数中进行手动确认。 cancelCallback: 当MQ服务出现问题，导致不能正常消费消息 (比如：队列被删除等)，则会调用该回调函数。此外，消费者也可以调用 channel.basicAck 手动取消该消费者 4 总结 生产者推送消息只需要 RoutingKey 和 Exchange 消费者建议手动 ack 确认，尽量保证消息不丢失 笔者建议生产者和消费者双方都需要进行创建队列的工作，因为不确定哪一方先启动 如果想要消息的持久化，必须保证交换器持久化、队列持久化]]></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识RabbitMQ]]></title>
    <url>%2F2019%2F05%2F26%2F%E5%88%9D%E8%AF%86RabbitMQ%2F</url>
    <content type="text"></content>
      <categories>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
</search>
